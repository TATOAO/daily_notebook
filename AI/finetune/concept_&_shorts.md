
PEFT.
Parameter-Efficient Fine-Tuning.

RLHF
Reinforcement Learning from Human Feedback (RLHF)

TL;DR Summarization (Too Long; Didn't read)


PPO
Proximal policy optimization (PPO) is an algorithm in the field of reinforcement learning that trains a computer agent's decision function to accomplish ...

[The N+ Implementation Details of RLHF with PPO: A
Case Study on TL;DR Summarization](https://arxiv.org/pdf/2403.17031 ":)")

(Proximal is the opposit of distal)




NEFtuning
Noisy Embedding Instruction Fine Tuning
embeddings.neftune_noise_alpha





# Data 

ChatML 
Chat Markup Language

